optimizer: adam
lr: 0.0001
optimizer_kwargs: {}
alpha: 12.0
w_decay: 0.0
ae_drop_out_rate: 0.4
mds_drop_out_rate: 0.0
ae_units: [1024, 512, 256]
ae_acts: ['relu', 'relu', 'relu']
mds_units: [1024, 512, 256]
mds_acts: ['relu', 'relu', None]
dist_name: euclidean
mds_loss: abs_s_stress
dist_eps: 1e-06
pretrain_step_num: 1000
max_step_num: 20000
min_step_num: 4000
early_stop_patience: 6
print_freq: 50
val_freq: 100
draw_freq: 500
save_model: False
fix_ae: False
verbose: True
batch_size: 256
validate_size: 2560
embed_batch_size: 2560
train_shuffle_buffer: 2560
train_interleave_cycle: 2
n_samples: 2746
n_features: 19771
issparse: True
dtype: float32
feed_type: sparse_mat
train_tfrecord_path: None
pred_tfrecord_path: None
Pretrain begin============================================
Step 50(5.0%): Batch Loss=494.993896484375
Step 100(10.0%): Batch Loss=473.5043029785156
Step 150(15.0%): Batch Loss=467.4969482421875
Step 200(20.0%): Batch Loss=458.2064514160156
Step 250(25.0%): Batch Loss=442.054931640625
Step 300(30.0%): Batch Loss=438.6500244140625
Step 350(35.0%): Batch Loss=435.038330078125
Step 400(40.0%): Batch Loss=435.931396484375
Step 450(45.0%): Batch Loss=428.78021240234375
Step 500(50.0%): Batch Loss=426.5481262207031
Step 550(55.0%): Batch Loss=438.0638427734375
Step 600(60.0%): Batch Loss=426.3196105957031
Step 650(65.0%): Batch Loss=436.6539001464844
Step 700(70.0%): Batch Loss=441.8128662109375
Step 750(75.0%): Batch Loss=438.4481201171875
Step 800(80.0%): Batch Loss=431.0198669433594
Step 850(85.0%): Batch Loss=427.2322692871094
Step 900(90.0%): Batch Loss=428.1187438964844
Step 950(95.0%): Batch Loss=432.5137634277344
Step 1000(100.0%): Batch Loss=412.89599609375
Pretrain end.============================================
Step 50(0.25%); Global Step 50: Batch Loss=584.4363403320312; [Reconstruct, MDS, L2] Loss = [523.41284, 5.085291, 0.0]
Step 100(0.5%); Global Step 100: Batch Loss=543.8501586914062; [Reconstruct, MDS, L2] Loss = [489.91974, 4.4941998, 0.0]
Step 100(0.5%); Global Step 100: Validation Loss=615.5892333984375; [Reconstruct, MDS, L2] Loss = [533.7464, 6.820236, 0.0]; Min Val Loss = 615.5892333984375; No Improve = 0; 
Step 150(0.75%); Global Step 150: Batch Loss=540.7661743164062; [Reconstruct, MDS, L2] Loss = [494.17722, 3.8824115, 0.0]
Step 200(1.0%); Global Step 200: Batch Loss=534.4894409179688; [Reconstruct, MDS, L2] Loss = [490.2782, 3.6842709, 0.0]
Step 200(1.0%); Global Step 200: Validation Loss=610.9859008789062; [Reconstruct, MDS, L2] Loss = [528.44885, 6.878081, 0.0]; Min Val Loss = 610.9859008789062; No Improve = 0; 
Step 250(1.25%); Global Step 250: Batch Loss=544.5559692382812; [Reconstruct, MDS, L2] Loss = [493.21588, 4.2783384, 0.0]
Step 300(1.5%); Global Step 300: Batch Loss=530.1444702148438; [Reconstruct, MDS, L2] Loss = [487.8215, 3.5269146, 0.0]
Step 300(1.5%); Global Step 300: Validation Loss=604.0652465820312; [Reconstruct, MDS, L2] Loss = [526.0391, 6.502176, 0.0]; Min Val Loss = 604.0652465820312; No Improve = 0; 
Step 350(1.75%); Global Step 350: Batch Loss=520.9974975585938; [Reconstruct, MDS, L2] Loss = [481.98627, 3.250938, 0.0]
Step 400(2.0%); Global Step 400: Batch Loss=524.8206787109375; [Reconstruct, MDS, L2] Loss = [480.83453, 3.6655128, 0.0]
Step 400(2.0%); Global Step 400: Validation Loss=617.0169677734375; [Reconstruct, MDS, L2] Loss = [524.39417, 7.718576, 0.0]; Min Val Loss = 604.0652465820312; No Improve = 1; 
Step 450(2.25%); Global Step 450: Batch Loss=534.055419921875; [Reconstruct, MDS, L2] Loss = [494.98358, 3.2559867, 0.0]
Step 500(2.5%); Global Step 500: Batch Loss=506.4178466796875; [Reconstruct, MDS, L2] Loss = [472.53693, 2.823409, 0.0]
Step 500(2.5%); Global Step 500: Validation Loss=607.0066528320312; [Reconstruct, MDS, L2] Loss = [521.1088, 7.1581497, 0.0]; Min Val Loss = 604.0652465820312; No Improve = 2; 
Step 550(2.75%); Global Step 550: Batch Loss=520.2672119140625; [Reconstruct, MDS, L2] Loss = [484.15268, 3.0095427, 0.0]
Step 600(3.0%); Global Step 600: Batch Loss=532.1052856445312; [Reconstruct, MDS, L2] Loss = [496.2169, 2.990702, 0.0]
Step 600(3.0%); Global Step 600: Validation Loss=614.9715576171875; [Reconstruct, MDS, L2] Loss = [517.9709, 8.083388, 0.0]; Min Val Loss = 604.0652465820312; No Improve = 3; 
Step 650(3.25%); Global Step 650: Batch Loss=520.7453002929688; [Reconstruct, MDS, L2] Loss = [489.53513, 2.6008494, 0.0]
Step 700(3.5%); Global Step 700: Batch Loss=514.5003662109375; [Reconstruct, MDS, L2] Loss = [483.54123, 2.579927, 0.0]
Step 700(3.5%); Global Step 700: Validation Loss=593.5442504882812; [Reconstruct, MDS, L2] Loss = [513.00116, 6.7119217, 0.0]; Min Val Loss = 593.5442504882812; No Improve = 0; 
Step 750(3.75%); Global Step 750: Batch Loss=526.7101440429688; [Reconstruct, MDS, L2] Loss = [491.65527, 2.9212408, 0.0]
Step 800(4.0%); Global Step 800: Batch Loss=527.9312133789062; [Reconstruct, MDS, L2] Loss = [497.4036, 2.5439687, 0.0]
Step 800(4.0%); Global Step 800: Validation Loss=588.0641479492188; [Reconstruct, MDS, L2] Loss = [507.88916, 6.6812477, 0.0]; Min Val Loss = 588.0641479492188; No Improve = 0; 
Step 850(4.25%); Global Step 850: Batch Loss=504.80023193359375; [Reconstruct, MDS, L2] Loss = [480.87308, 1.9939289, 0.0]
Step 900(4.5%); Global Step 900: Batch Loss=506.5609130859375; [Reconstruct, MDS, L2] Loss = [482.06512, 2.0413163, 0.0]
Step 900(4.5%); Global Step 900: Validation Loss=584.327392578125; [Reconstruct, MDS, L2] Loss = [504.10693, 6.6850395, 0.0]; Min Val Loss = 584.327392578125; No Improve = 0; 
Step 950(4.75%); Global Step 950: Batch Loss=508.4351501464844; [Reconstruct, MDS, L2] Loss = [483.29745, 2.0948079, 0.0]
Step 1000(5.0%); Global Step 1000: Batch Loss=511.86065673828125; [Reconstruct, MDS, L2] Loss = [487.4591, 2.0334628, 0.0]
Step 1000(5.0%); Global Step 1000: Validation Loss=580.3761596679688; [Reconstruct, MDS, L2] Loss = [498.63745, 6.8115616, 0.0]; Min Val Loss = 580.3761596679688; No Improve = 0; 
Step 1050(5.25%); Global Step 1050: Batch Loss=499.7007751464844; [Reconstruct, MDS, L2] Loss = [478.68103, 1.7516445, 0.0]
Step 1100(5.5%); Global Step 1100: Batch Loss=514.1180419921875; [Reconstruct, MDS, L2] Loss = [490.10748, 2.0008776, 0.0]
Step 1100(5.5%); Global Step 1100: Validation Loss=556.4915771484375; [Reconstruct, MDS, L2] Loss = [493.61124, 5.2400327, 0.0]; Min Val Loss = 556.4915771484375; No Improve = 0; 
Step 1150(5.75%); Global Step 1150: Batch Loss=492.0463562011719; [Reconstruct, MDS, L2] Loss = [471.8644, 1.6818279, 0.0]
Step 1200(6.0%); Global Step 1200: Batch Loss=503.736328125; [Reconstruct, MDS, L2] Loss = [482.85043, 1.7404907, 0.0]
Step 1200(6.0%); Global Step 1200: Validation Loss=563.4241943359375; [Reconstruct, MDS, L2] Loss = [490.06195, 6.1135244, 0.0]; Min Val Loss = 556.4915771484375; No Improve = 1; 
Step 1250(6.25%); Global Step 1250: Batch Loss=509.5284118652344; [Reconstruct, MDS, L2] Loss = [484.77737, 2.0625858, 0.0]
Step 1300(6.5%); Global Step 1300: Batch Loss=512.572509765625; [Reconstruct, MDS, L2] Loss = [490.4654, 1.842262, 0.0]
Step 1300(6.5%); Global Step 1300: Validation Loss=560.6780395507812; [Reconstruct, MDS, L2] Loss = [487.23016, 6.1206565, 0.0]; Min Val Loss = 556.4915771484375; No Improve = 2; 
Step 1350(6.75%); Global Step 1350: Batch Loss=491.9195251464844; [Reconstruct, MDS, L2] Loss = [470.36615, 1.7961143, 0.0]
Step 1400(7.0%); Global Step 1400: Batch Loss=496.15435791015625; [Reconstruct, MDS, L2] Loss = [475.8089, 1.6954554, 0.0]
Step 1400(7.0%); Global Step 1400: Validation Loss=548.62109375; [Reconstruct, MDS, L2] Loss = [483.70566, 5.409618, 0.0]; Min Val Loss = 548.62109375; No Improve = 0; 
Step 1450(7.25%); Global Step 1450: Batch Loss=506.3993225097656; [Reconstruct, MDS, L2] Loss = [486.2604, 1.6782436, 0.0]
Step 1500(7.5%); Global Step 1500: Batch Loss=493.1611328125; [Reconstruct, MDS, L2] Loss = [469.01657, 2.0120463, 0.0]
Step 1500(7.5%); Global Step 1500: Validation Loss=552.7225341796875; [Reconstruct, MDS, L2] Loss = [481.44818, 5.9395347, 0.0]; Min Val Loss = 548.62109375; No Improve = 1; 
Step 1550(7.75%); Global Step 1550: Batch Loss=491.5987854003906; [Reconstruct, MDS, L2] Loss = [469.68927, 1.825792, 0.0]
Step 1600(8.0%); Global Step 1600: Batch Loss=506.92083740234375; [Reconstruct, MDS, L2] Loss = [486.2373, 1.7236282, 0.0]
Step 1600(8.0%); Global Step 1600: Validation Loss=530.2906494140625; [Reconstruct, MDS, L2] Loss = [477.86093, 4.369139, 0.0]; Min Val Loss = 530.2906494140625; No Improve = 0; 
Step 1650(8.25%); Global Step 1650: Batch Loss=495.9319763183594; [Reconstruct, MDS, L2] Loss = [473.98676, 1.828768, 0.0]
Step 1700(8.5%); Global Step 1700: Batch Loss=496.0016784667969; [Reconstruct, MDS, L2] Loss = [473.98566, 1.8346686, 0.0]
Step 1700(8.5%); Global Step 1700: Validation Loss=515.6502685546875; [Reconstruct, MDS, L2] Loss = [476.10474, 3.295459, 0.0]; Min Val Loss = 515.6502685546875; No Improve = 0; 
Step 1750(8.75%); Global Step 1750: Batch Loss=493.61285400390625; [Reconstruct, MDS, L2] Loss = [474.90262, 1.559186, 0.0]
Step 1800(9.0%); Global Step 1800: Batch Loss=489.29339599609375; [Reconstruct, MDS, L2] Loss = [469.5018, 1.6492987, 0.0]
Step 1800(9.0%); Global Step 1800: Validation Loss=531.4971923828125; [Reconstruct, MDS, L2] Loss = [475.46442, 4.6693997, 0.0]; Min Val Loss = 515.6502685546875; No Improve = 1; 
Step 1850(9.25%); Global Step 1850: Batch Loss=494.6231384277344; [Reconstruct, MDS, L2] Loss = [470.06387, 2.046605, 0.0]
Step 1900(9.5%); Global Step 1900: Batch Loss=497.71331787109375; [Reconstruct, MDS, L2] Loss = [478.04617, 1.6389288, 0.0]
Step 1900(9.5%); Global Step 1900: Validation Loss=519.5367431640625; [Reconstruct, MDS, L2] Loss = [473.18878, 3.8623319, 0.0]; Min Val Loss = 515.6502685546875; No Improve = 2; 
Step 1950(9.75%); Global Step 1950: Batch Loss=484.7301330566406; [Reconstruct, MDS, L2] Loss = [464.55328, 1.6814045, 0.0]
Step 2000(10.0%); Global Step 2000: Batch Loss=495.520751953125; [Reconstruct, MDS, L2] Loss = [468.49716, 2.2519655, 0.0]
Step 2000(10.0%); Global Step 2000: Validation Loss=498.0045471191406; [Reconstruct, MDS, L2] Loss = [470.97348, 2.2525864, 0.0]; Min Val Loss = 498.0045471191406; No Improve = 0; 
Step 2050(10.25%); Global Step 2050: Batch Loss=493.47210693359375; [Reconstruct, MDS, L2] Loss = [470.9899, 1.8735161, 0.0]
Step 2100(10.5%); Global Step 2100: Batch Loss=488.8976135253906; [Reconstruct, MDS, L2] Loss = [465.1412, 1.9797006, 0.0]
Step 2100(10.5%); Global Step 2100: Validation Loss=496.75592041015625; [Reconstruct, MDS, L2] Loss = [470.20612, 2.2124796, 0.0]; Min Val Loss = 496.75592041015625; No Improve = 0; 
Step 2150(10.75%); Global Step 2150: Batch Loss=494.6104736328125; [Reconstruct, MDS, L2] Loss = [472.97968, 1.8025668, 0.0]
Step 2200(11.0%); Global Step 2200: Batch Loss=483.2336730957031; [Reconstruct, MDS, L2] Loss = [464.56403, 1.5558031, 0.0]
Step 2200(11.0%); Global Step 2200: Validation Loss=504.673828125; [Reconstruct, MDS, L2] Loss = [469.119, 2.9629023, 0.0]; Min Val Loss = 496.75592041015625; No Improve = 1; 
Step 2250(11.25%); Global Step 2250: Batch Loss=491.26788330078125; [Reconstruct, MDS, L2] Loss = [468.38202, 1.9071547, 0.0]
Step 2300(11.5%); Global Step 2300: Batch Loss=483.1581115722656; [Reconstruct, MDS, L2] Loss = [456.89685, 2.188439, 0.0]
Step 2300(11.5%); Global Step 2300: Validation Loss=487.676513671875; [Reconstruct, MDS, L2] Loss = [467.3105, 1.6971716, 0.0]; Min Val Loss = 487.676513671875; No Improve = 0; 
Step 2350(11.75%); Global Step 2350: Batch Loss=477.2610168457031; [Reconstruct, MDS, L2] Loss = [458.9752, 1.5238192, 0.0]
Step 2400(12.0%); Global Step 2400: Batch Loss=485.73736572265625; [Reconstruct, MDS, L2] Loss = [468.94775, 1.3991354, 0.0]
Step 2400(12.0%); Global Step 2400: Validation Loss=495.08319091796875; [Reconstruct, MDS, L2] Loss = [466.68744, 2.3663163, 0.0]; Min Val Loss = 487.676513671875; No Improve = 1; 
Step 2450(12.25%); Global Step 2450: Batch Loss=491.3135070800781; [Reconstruct, MDS, L2] Loss = [465.13373, 2.1816473, 0.0]
Step 2500(12.5%); Global Step 2500: Batch Loss=483.0726318359375; [Reconstruct, MDS, L2] Loss = [465.581, 1.4576378, 0.0]
Step 2500(12.5%); Global Step 2500: Validation Loss=487.85479736328125; [Reconstruct, MDS, L2] Loss = [465.40225, 1.8710438, 0.0]; Min Val Loss = 487.676513671875; No Improve = 2; 
Step 2550(12.75%); Global Step 2550: Batch Loss=491.3514099121094; [Reconstruct, MDS, L2] Loss = [466.86996, 2.04012, 0.0]
Step 2600(13.0%); Global Step 2600: Batch Loss=474.7047424316406; [Reconstruct, MDS, L2] Loss = [458.67758, 1.3355963, 0.0]
Step 2600(13.0%); Global Step 2600: Validation Loss=494.03460693359375; [Reconstruct, MDS, L2] Loss = [464.462, 2.4643853, 0.0]; Min Val Loss = 487.676513671875; No Improve = 3; 
Step 2650(13.25%); Global Step 2650: Batch Loss=500.50823974609375; [Reconstruct, MDS, L2] Loss = [466.72656, 2.8151398, 0.0]
Step 2700(13.5%); Global Step 2700: Batch Loss=493.6180419921875; [Reconstruct, MDS, L2] Loss = [470.44882, 1.9307673, 0.0]
Step 2700(13.5%); Global Step 2700: Validation Loss=500.16766357421875; [Reconstruct, MDS, L2] Loss = [464.15204, 3.0013041, 0.0]; Min Val Loss = 487.676513671875; No Improve = 4; 
Step 2750(13.75%); Global Step 2750: Batch Loss=482.0437927246094; [Reconstruct, MDS, L2] Loss = [461.90485, 1.6782463, 0.0]
Step 2800(14.0%); Global Step 2800: Batch Loss=490.3508605957031; [Reconstruct, MDS, L2] Loss = [467.16803, 1.9319028, 0.0]
Step 2800(14.0%); Global Step 2800: Validation Loss=480.78741455078125; [Reconstruct, MDS, L2] Loss = [462.17618, 1.5509369, 0.0]; Min Val Loss = 480.78741455078125; No Improve = 0; 
Step 2850(14.25%); Global Step 2850: Batch Loss=493.5562744140625; [Reconstruct, MDS, L2] Loss = [468.6935, 2.0718968, 0.0]
Step 2900(14.5%); Global Step 2900: Batch Loss=494.6318054199219; [Reconstruct, MDS, L2] Loss = [467.62357, 2.2506857, 0.0]
Step 2900(14.5%); Global Step 2900: Validation Loss=500.59320068359375; [Reconstruct, MDS, L2] Loss = [462.60977, 3.1652899, 0.0]; Min Val Loss = 480.78741455078125; No Improve = 1; 
Step 2950(14.75%); Global Step 2950: Batch Loss=477.9212951660156; [Reconstruct, MDS, L2] Loss = [461.2607, 1.3883829, 0.0]
Step 3000(15.0%); Global Step 3000: Batch Loss=476.0703125; [Reconstruct, MDS, L2] Loss = [458.00983, 1.5050417, 0.0]
Step 3000(15.0%); Global Step 3000: Validation Loss=483.114990234375; [Reconstruct, MDS, L2] Loss = [461.61523, 1.7916434, 0.0]; Min Val Loss = 480.78741455078125; No Improve = 2; 
Step 3050(15.25%); Global Step 3050: Batch Loss=474.54296875; [Reconstruct, MDS, L2] Loss = [455.5999, 1.578589, 0.0]
Step 3100(15.5%); Global Step 3100: Batch Loss=481.4493713378906; [Reconstruct, MDS, L2] Loss = [464.57495, 1.4062022, 0.0]
Step 3100(15.5%); Global Step 3100: Validation Loss=484.7420959472656; [Reconstruct, MDS, L2] Loss = [460.8807, 1.988447, 0.0]; Min Val Loss = 480.78741455078125; No Improve = 3; 
Step 3150(15.75%); Global Step 3150: Batch Loss=479.6757507324219; [Reconstruct, MDS, L2] Loss = [457.30295, 1.8644006, 0.0]
Step 3200(16.0%); Global Step 3200: Batch Loss=480.1434326171875; [Reconstruct, MDS, L2] Loss = [459.72308, 1.701695, 0.0]
Step 3200(16.0%); Global Step 3200: Validation Loss=486.0265197753906; [Reconstruct, MDS, L2] Loss = [459.98276, 2.1703105, 0.0]; Min Val Loss = 480.78741455078125; No Improve = 4; 
Step 3250(16.25%); Global Step 3250: Batch Loss=471.5864562988281; [Reconstruct, MDS, L2] Loss = [457.81378, 1.1477237, 0.0]
Step 3300(16.5%); Global Step 3300: Batch Loss=480.4236755371094; [Reconstruct, MDS, L2] Loss = [461.7859, 1.5531492, 0.0]
Step 3300(16.5%); Global Step 3300: Validation Loss=476.8094787597656; [Reconstruct, MDS, L2] Loss = [459.333, 1.4563706, 0.0]; Min Val Loss = 476.8094787597656; No Improve = 0; 
Step 3350(16.75%); Global Step 3350: Batch Loss=478.903564453125; [Reconstruct, MDS, L2] Loss = [462.06888, 1.4028913, 0.0]
Step 3400(17.0%); Global Step 3400: Batch Loss=475.0111999511719; [Reconstruct, MDS, L2] Loss = [459.85516, 1.2630029, 0.0]
Step 3400(17.0%); Global Step 3400: Validation Loss=477.11712646484375; [Reconstruct, MDS, L2] Loss = [457.80035, 1.6097383, 0.0]; Min Val Loss = 476.8094787597656; No Improve = 1; 
Step 3450(17.25%); Global Step 3450: Batch Loss=471.59100341796875; [Reconstruct, MDS, L2] Loss = [452.38046, 1.6008787, 0.0]
Step 3500(17.5%); Global Step 3500: Batch Loss=482.4267578125; [Reconstruct, MDS, L2] Loss = [465.53503, 1.4076442, 0.0]
Step 3500(17.5%); Global Step 3500: Validation Loss=474.59588623046875; [Reconstruct, MDS, L2] Loss = [457.64703, 1.4124092, 0.0]; Min Val Loss = 474.59588623046875; No Improve = 0; 
Step 3550(17.75%); Global Step 3550: Batch Loss=475.53045654296875; [Reconstruct, MDS, L2] Loss = [456.7448, 1.5654714, 0.0]
Step 3600(18.0%); Global Step 3600: Batch Loss=473.216064453125; [Reconstruct, MDS, L2] Loss = [455.3085, 1.4922957, 0.0]
Step 3600(18.0%); Global Step 3600: Validation Loss=475.5298767089844; [Reconstruct, MDS, L2] Loss = [457.20996, 1.5266645, 0.0]; Min Val Loss = 474.59588623046875; No Improve = 1; 
Step 3650(18.25%); Global Step 3650: Batch Loss=488.97442626953125; [Reconstruct, MDS, L2] Loss = [459.0451, 2.4941106, 0.0]
Step 3700(18.5%); Global Step 3700: Batch Loss=466.02520751953125; [Reconstruct, MDS, L2] Loss = [441.19662, 2.0690491, 0.0]
Step 3700(18.5%); Global Step 3700: Validation Loss=487.52557373046875; [Reconstruct, MDS, L2] Loss = [457.35602, 2.5141342, 0.0]; Min Val Loss = 474.59588623046875; No Improve = 2; 
Step 3750(18.75%); Global Step 3750: Batch Loss=475.8967590332031; [Reconstruct, MDS, L2] Loss = [460.7046, 1.266013, 0.0]
Step 3800(19.0%); Global Step 3800: Batch Loss=467.0102233886719; [Reconstruct, MDS, L2] Loss = [446.95355, 1.6713885, 0.0]
Step 3800(19.0%); Global Step 3800: Validation Loss=483.29644775390625; [Reconstruct, MDS, L2] Loss = [456.0891, 2.267278, 0.0]; Min Val Loss = 474.59588623046875; No Improve = 3; 
Step 3850(19.25%); Global Step 3850: Batch Loss=473.9886779785156; [Reconstruct, MDS, L2] Loss = [454.54492, 1.6203132, 0.0]
Step 3900(19.5%); Global Step 3900: Batch Loss=485.7141418457031; [Reconstruct, MDS, L2] Loss = [464.90552, 1.7340509, 0.0]
Step 3900(19.5%); Global Step 3900: Validation Loss=478.66595458984375; [Reconstruct, MDS, L2] Loss = [455.73047, 1.9112895, 0.0]; Min Val Loss = 474.59588623046875; No Improve = 4; 
Step 3950(19.75%); Global Step 3950: Batch Loss=477.2166748046875; [Reconstruct, MDS, L2] Loss = [458.90198, 1.5262234, 0.0]
Step 4000(20.0%); Global Step 4000: Batch Loss=484.49273681640625; [Reconstruct, MDS, L2] Loss = [457.8963, 2.2163699, 0.0]
Step 4000(20.0%); Global Step 4000: Validation Loss=486.7854919433594; [Reconstruct, MDS, L2] Loss = [455.0503, 2.6446023, 0.0]; Min Val Loss = 474.59588623046875; No Improve = 5; 
Step 4050(20.25%); Global Step 4050: Batch Loss=486.4526062011719; [Reconstruct, MDS, L2] Loss = [456.87048, 2.4651775, 0.0]
Step 4100(20.5%); Global Step 4100: Batch Loss=470.7084655761719; [Reconstruct, MDS, L2] Loss = [454.5719, 1.3447143, 0.0]
Step 4100(20.5%); Global Step 4100: Validation Loss=469.8978576660156; [Reconstruct, MDS, L2] Loss = [455.02515, 1.2393914, 0.0]; Min Val Loss = 469.8978576660156; No Improve = 0; 
Step 4150(20.75%); Global Step 4150: Batch Loss=483.3712158203125; [Reconstruct, MDS, L2] Loss = [458.06778, 2.1086192, 0.0]
Step 4200(21.0%); Global Step 4200: Batch Loss=465.0908508300781; [Reconstruct, MDS, L2] Loss = [445.1747, 1.6596788, 0.0]
Step 4200(21.0%); Global Step 4200: Validation Loss=478.53265380859375; [Reconstruct, MDS, L2] Loss = [454.73984, 1.9827343, 0.0]; Min Val Loss = 469.8978576660156; No Improve = 1; 
Step 4250(21.25%); Global Step 4250: Batch Loss=465.9458312988281; [Reconstruct, MDS, L2] Loss = [448.6541, 1.440977, 0.0]
Step 4300(21.5%); Global Step 4300: Batch Loss=477.9444580078125; [Reconstruct, MDS, L2] Loss = [458.30698, 1.6364559, 0.0]
Step 4300(21.5%); Global Step 4300: Validation Loss=469.71759033203125; [Reconstruct, MDS, L2] Loss = [453.96225, 1.3129444, 0.0]; Min Val Loss = 469.71759033203125; No Improve = 0; 
Step 4350(21.75%); Global Step 4350: Batch Loss=468.07037353515625; [Reconstruct, MDS, L2] Loss = [447.74924, 1.6934279, 0.0]
Step 4400(22.0%); Global Step 4400: Batch Loss=479.6006774902344; [Reconstruct, MDS, L2] Loss = [458.92, 1.7233876, 0.0]
Step 4400(22.0%); Global Step 4400: Validation Loss=479.79010009765625; [Reconstruct, MDS, L2] Loss = [453.6411, 2.1790814, 0.0]; Min Val Loss = 469.71759033203125; No Improve = 1; 
Step 4450(22.25%); Global Step 4450: Batch Loss=470.8387756347656; [Reconstruct, MDS, L2] Loss = [454.44763, 1.3659278, 0.0]
Step 4500(22.5%); Global Step 4500: Batch Loss=473.50341796875; [Reconstruct, MDS, L2] Loss = [451.8054, 1.8081682, 0.0]
Step 4500(22.5%); Global Step 4500: Validation Loss=476.95196533203125; [Reconstruct, MDS, L2] Loss = [453.43536, 1.9597158, 0.0]; Min Val Loss = 469.71759033203125; No Improve = 2; 
Step 4550(22.75%); Global Step 4550: Batch Loss=463.2799377441406; [Reconstruct, MDS, L2] Loss = [445.4006, 1.4899434, 0.0]
Step 4600(23.0%); Global Step 4600: Batch Loss=466.96697998046875; [Reconstruct, MDS, L2] Loss = [450.42532, 1.3784707, 0.0]
Step 4600(23.0%); Global Step 4600: Validation Loss=467.6856384277344; [Reconstruct, MDS, L2] Loss = [452.37402, 1.2759705, 0.0]; Min Val Loss = 467.6856384277344; No Improve = 0; 
Step 4650(23.25%); Global Step 4650: Batch Loss=476.9212951660156; [Reconstruct, MDS, L2] Loss = [453.72855, 1.932728, 0.0]
Step 4700(23.5%); Global Step 4700: Batch Loss=472.96124267578125; [Reconstruct, MDS, L2] Loss = [458.16223, 1.2332518, 0.0]
Step 4700(23.5%); Global Step 4700: Validation Loss=468.8407287597656; [Reconstruct, MDS, L2] Loss = [452.76434, 1.3396946, 0.0]; Min Val Loss = 467.6856384277344; No Improve = 1; 
Step 4750(23.75%); Global Step 4750: Batch Loss=482.2198486328125; [Reconstruct, MDS, L2] Loss = [454.11105, 2.3423996, 0.0]
Step 4800(24.0%); Global Step 4800: Batch Loss=490.86920166015625; [Reconstruct, MDS, L2] Loss = [462.5736, 2.3579652, 0.0]
Step 4800(24.0%); Global Step 4800: Validation Loss=472.1787109375; [Reconstruct, MDS, L2] Loss = [453.10712, 1.5893013, 0.0]; Min Val Loss = 467.6856384277344; No Improve = 2; 
Step 4850(24.25%); Global Step 4850: Batch Loss=487.5454406738281; [Reconstruct, MDS, L2] Loss = [469.39426, 1.5125995, 0.0]
Step 4900(24.5%); Global Step 4900: Batch Loss=466.2090759277344; [Reconstruct, MDS, L2] Loss = [449.73093, 1.3731793, 0.0]
Step 4900(24.5%); Global Step 4900: Validation Loss=468.66815185546875; [Reconstruct, MDS, L2] Loss = [452.06073, 1.3839533, 0.0]; Min Val Loss = 467.6856384277344; No Improve = 3; 
Step 4950(24.75%); Global Step 4950: Batch Loss=463.94866943359375; [Reconstruct, MDS, L2] Loss = [446.26465, 1.4736693, 0.0]
Step 5000(25.0%); Global Step 5000: Batch Loss=463.3529357910156; [Reconstruct, MDS, L2] Loss = [443.82483, 1.6273429, 0.0]
Step 5000(25.0%); Global Step 5000: Validation Loss=468.06280517578125; [Reconstruct, MDS, L2] Loss = [451.8207, 1.3535035, 0.0]; Min Val Loss = 467.6856384277344; No Improve = 4; 
Step 5050(25.25%); Global Step 5050: Batch Loss=478.39044189453125; [Reconstruct, MDS, L2] Loss = [454.45154, 1.9949096, 0.0]
Step 5100(25.5%); Global Step 5100: Batch Loss=458.1638488769531; [Reconstruct, MDS, L2] Loss = [441.1256, 1.4198539, 0.0]
Step 5100(25.5%); Global Step 5100: Validation Loss=468.5406188964844; [Reconstruct, MDS, L2] Loss = [451.28278, 1.4381549, 0.0]; Min Val Loss = 467.6856384277344; No Improve = 5; 
Step 5150(25.75%); Global Step 5150: Batch Loss=468.8702392578125; [Reconstruct, MDS, L2] Loss = [450.14258, 1.5606391, 0.0]
Step 5200(26.0%); Global Step 5200: Batch Loss=459.5696716308594; [Reconstruct, MDS, L2] Loss = [443.746, 1.3186402, 0.0]
No improve = 6, early stop!
Training end. Total step = 5200
